{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-12T21:45:09.196712Z",
     "start_time": "2020-11-12T21:45:06.395813Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = 100\n",
    "\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.utils import resample\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/final_startup_data.csv', index_col=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling continous variable columns in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating instance of scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Creating list of columns with continuous variables to be scaled\n",
    "columns_to_scale = ['funding_total_usd',\n",
    "                    'seed',\n",
    "                    'venture',\n",
    "                    'equity_crowdfunding',\n",
    "                    'undisclosed',\n",
    "                    'convertible_note',\n",
    "                    'debt_financing',\n",
    "                    'angel',\n",
    "                    'grant',\n",
    "                    'private_equity', \n",
    "                    'round_A', \n",
    "                    'round_B',\n",
    "                    'days_from_founding_to_funding',\n",
    "                    'time_between_first_and_last_funding']\n",
    "\n",
    "# Scaling continuous variable columns\n",
    "data[columns_to_scale] = scaler.fit_transform(data[columns_to_scale])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Train Split for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting dataset into train and test sets\n",
    "train, test = train_test_split(data, test_size=0.2, random_state = 42)\n",
    "\n",
    "# Creating X,y for train\n",
    "X_train = train.drop(columns = 'target')\n",
    "y_train = train.target\n",
    "\n",
    "# Creating X,y for test\n",
    "X_test = test.drop(columns = 'target')\n",
    "y_test = test.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting and Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-12T14:37:20.707601Z",
     "start_time": "2020-11-12T14:36:35.085650Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating instance of Logistic Regression for baseline model\n",
    "base_logreg = LogisticRegression(random_state=42, max_iter= 10**4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-12T14:37:20.707601Z",
     "start_time": "2020-11-12T14:36:35.085650Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fitting baseline model\n",
    "base_logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-12T14:37:43.068982Z",
     "start_time": "2020-11-12T14:37:43.025583Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94     12873\n",
      "           1       0.09      0.01      0.02      1505\n",
      "\n",
      "    accuracy                           0.89     14378\n",
      "   macro avg       0.50      0.50      0.48     14378\n",
      "weighted avg       0.81      0.89      0.84     14378\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predicting on train set\n",
    "y_base_log_train_preds = base_logreg.predict(X_train)\n",
    "\n",
    "# Testing target variables prediction against real for training set\n",
    "print(classification_report(y_train, y_base_log_train_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-12T14:38:13.616897Z",
     "start_time": "2020-11-12T14:38:13.582801Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12711,   162],\n",
       "       [ 1488,    17]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating confusion matrix for y_train and y_base_preds_train\n",
    "confusion_matrix(y_train, y_base_log_train_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting on test set\n",
    "y_base_log_test_preds = base_logreg.predict(X_test)\n",
    "\n",
    "# Testing target variables prediction against real for test set\n",
    "print(classification_report(y_test, y_base_log_test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating confusion matrix for y_test and y_base_preds_test\n",
    "confusion_matrix(y_test, y_base_log_test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling with Downsampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing With Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsetting observation with target variable value 1\n",
    "acquired_down = train[train.target ==1]\n",
    "\n",
    "# Subsetting observation with target variable value 0\n",
    "not_acquired_down = train[train.target ==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsampling majority class (0) with replacement to be equal to minority class (1) \n",
    "not_acquired_downsampled = resample(not_acquired,\n",
    "                                replace = True, \n",
    "                                n_samples = (len(acquired)), \n",
    "                                random_state = 23) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new downsampled dataset df_down\n",
    "df_down = pd.concat([acquired_down, not_acquired_downsampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1875\n",
       "0    1875\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Showing new balanced value counts for target variable\n",
    "df_down.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new X for downsampled model training\n",
    "X_down = df_down.drop(columns='target')\n",
    "\n",
    "# Creating new X for downsampled model training\n",
    "y_down = df_down.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new instance of Logistic Regression model\n",
    "logReg = LogisticRegression(class_weight = 'balanced',\n",
    "                            C=0.01,\n",
    "                            solver='saga', \n",
    "                            penalty='elasticnet',\n",
    "                            max_iter=2000, \n",
    "                            l1_ratio=1.0\n",
    "                            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, class_weight='balanced', l1_ratio=1.0, max_iter=2000,\n",
       "                   penalty='elasticnet', solver='saga')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting downsampled dataset df_down to model for training\n",
    "logReg.fit(X_down, y_down)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.60      0.60      1515\n",
      "           1       0.59      0.59      0.59      1485\n",
      "\n",
      "    accuracy                           0.60      3000\n",
      "   macro avg       0.60      0.60      0.60      3000\n",
      "weighted avg       0.60      0.60      0.60      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using trained model to predict on downsampled train set\n",
    "y_down_log_train_preds = logReg.predict(X_down)\n",
    "\n",
    "# Testing target variables prediction against real for train set\n",
    "print(classification_report(y_down, y_down_log_train_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating confusion matrix for y_down and y_down_pred_train\n",
    "confusion_matrix(y_down, y_down_log_train_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.59      0.60       364\n",
      "           1       0.62      0.63      0.62       386\n",
      "\n",
      "    accuracy                           0.61       750\n",
      "   macro avg       0.61      0.61      0.61       750\n",
      "weighted avg       0.61      0.61      0.61       750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using trained model to predict on downsampled test set\n",
    "y_down_log_test_preds = logReg.predict(X_test)\n",
    "\n",
    "# Testing target variables prediction against real for test set\n",
    "print(classification_report(y_test, y_down_log_test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating confusion matrix for y_test and y_down_pred_test\n",
    "confusion_matrix(y_test, y_down_log_test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearch Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating parameter grid for GridSearch\n",
    "param_grid_down = { \n",
    "    'solver': ['saga'],\n",
    "    'C':[.3, .5],\n",
    "    'penalty':['elasticnet'],\n",
    "    'max_iter':[200, 1000],\n",
    "    'l1_ratio':[.2, 1.0]\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating instance of GridSearch for logistic regression including param_grid_down\n",
    "grid_tree=GridSearchCV(LogisticRegression(), param_grid_down, verbose=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  7.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=LogisticRegression(), n_jobs=-1,\n",
       "             param_grid={'C': [0.3, 0.5], 'l1_ratio': [0.2, 1.0],\n",
       "                         'max_iter': [200, 1000], 'penalty': ['elasticnet'],\n",
       "                         'solver': ['saga']},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting downsampled training data to GridSearch instance\n",
    "grid_tree.fit(X_down, y_down)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using trained model to predict on downsampled train set\n",
    "y_down_grid_train_preds = grid_tree.best_estimator_.predict(X_down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.71      0.72       360\n",
      "           1       0.74      0.75      0.74       390\n",
      "\n",
      "    accuracy                           0.73       750\n",
      "   macro avg       0.73      0.73      0.73       750\n",
      "weighted avg       0.73      0.73      0.73       750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing target variables prediction against real for train set\n",
    "print(classification_report(y_down, y_down_grid_train_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating confusion matrix for y_down and y_down_grid_train_preds\n",
    "confusion_matrix(y_down, y_down_grid_train_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using trained model to predict on downsampled test set\n",
    "y_down_grid_test_preds = grid_tree.best_estimator_.predict(X_down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.71      0.72       360\n",
      "           1       0.74      0.75      0.74       390\n",
      "\n",
      "    accuracy                           0.73       750\n",
      "   macro avg       0.73      0.73      0.73       750\n",
      "weighted avg       0.73      0.73      0.73       750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing target variables prediction against real for test set\n",
    "print(classification_report(y_test, y_down_grid_test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating confusion matrix for y_down and y_down_grid_test_preds\n",
    "confusion_matrix(y_down, y_down_grid_test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting and testing thresholds to maximize precision score\n",
    "THRESHOLD_down = 0.3\n",
    "y_pred_prob = grid_tree.predict_proba(X_test)[:, 1]\n",
    "y_pred_class = np.where(y_pred_prob > THRESHOLD_down, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling with Downsampling and Upsampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing With Class Imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upsampling Acquired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsetting observation with target variable value 1\n",
    "acquired_up = train[train.target == 1]\n",
    "\n",
    "# Subsetting observation with target variable value 0\n",
    "not_acquired_up = train[train.target == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upsampling minority class (1) with replacement to be equal to 5000 observations\n",
    "acquired_upsampled = resample(acquired_up,\n",
    "                              replace=True, \n",
    "                              n_samples=5000, \n",
    "                              random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new upsampled dataset df_up\n",
    "df_up = pd.concat([not_acquired_up, acquired_upsampled])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downsampling Not Acquired"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsetting observation with target variable value 0\n",
    "not_acquired_up_down = upsampled_data[upsampled_data.target == 0]\n",
    "\n",
    "# Subsetting observation with target variable value 1\n",
    "acquired_up_down = upsampled_data[upsampled_data.target == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsampling majority class (0) with replacement to be equal to 10000 observations\n",
    "not_acquired_downsampled = resample(not_acquired_up_down,\n",
    "                                 replace=True, \n",
    "                                 n_samples=10000, \n",
    "                                 random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new upsampled and downsampled dataset df_up_down\n",
    "df_up_down = pd.concat([acquired_up_down, not_acquired_downsampled])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tomek Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating X,y from df_up_down to use for Tomek Links\n",
    "X_up_down = df_up_down.drop('target', axis=1)\n",
    "y_up_down = df_up_down['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Tomek Links to df_up_down\n",
    "X_links, y_links = TomekLinks().fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistc Regression using GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new instance of Logistic Regression model\n",
    "lr_links = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating parameter grid for GridSearch\n",
    "param_grid_links_lr = {\n",
    "    \n",
    "    'class_weight': [None,'balanced'],\n",
    "    'solver': ['liblinear','sag','saga'],\n",
    "    'max_iter': list(range(100,1000,25)) \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating instance of GridSearch for logistic regression including param_grid_links_lr\n",
    "lr_links_grid = RandomizedSearchCV(lr_links, \n",
    "                             param_grid_links_lr, \n",
    "                             scoring='precision', \n",
    "                             n_jobs=-1, \n",
    "                             verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting up and downsampled training data to GridSearch instance\n",
    "lr_links_grid.fit(X_links, y_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using trained model to predict on up and downsampled train set\n",
    "y_links_grid_train_preds = lr_links_grid.predict(X_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing target variables prediction against real for train set\n",
    "print(classification_report(y_links, y_links_grid_train_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating confusion matrix for y_test and y_links_grid_test_preds\n",
    "confusion_matrix(y_links, y_links_grid_train_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using trained model to predict on up and downsampled test set\n",
    "y_links_grid_test_preds = lr_links_grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.05      0.09      1954\n",
      "           1       0.35      0.98      0.52      1046\n",
      "\n",
      "    accuracy                           0.37      3000\n",
      "   macro avg       0.58      0.51      0.31      3000\n",
      "weighted avg       0.65      0.37      0.24      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing target variables prediction against real for test set\n",
    "print(classification_report(y_test, y_links_grid_test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating confusion matrix for y_test and y_links_grid_test_preds\n",
    "confusion_matrix(y_test, y_links_grid_test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 0.95\n",
    "thesh_preds = np.where(lr.predict_proba(X_test)[:,1] > THRESHOLD, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new instance of Random Forest model\n",
    "rf_links = RandomForestClassifier(n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating parameter grid for Randomized Search\n",
    "param_grid_links_rf = {  \n",
    "    'n_estimators': [100,200,300],\n",
    "    'criterion': ['gini','entropy'],\n",
    "    'max_depth': list(range(5,7)),\n",
    "    'max_features': list(range(100,1000,100)),\n",
    "    'min_samples_leaf': [1,2,3,4,5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating instance of Randomized Search for Random Forest including param_grid_links_rf\n",
    "grid_tree_rf = RandomizedSearchCV(rf_links, \n",
    "                                  param_grid_links_rf, \n",
    "                                  cv=5,\n",
    "                                  verbose=1,\n",
    "                                  n_jobs=-1,\n",
    "                                  scoring='precision_micro'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  4.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(n_jobs=-1), n_jobs=-1,\n",
       "                   param_distributions={'criterion': ['gini', 'entropy'],\n",
       "                                        'max_depth': [5, 6],\n",
       "                                        'max_features': [100, 200, 300, 400,\n",
       "                                                         500, 600, 700, 800,\n",
       "                                                         900],\n",
       "                                        'min_samples_leaf': [1, 2, 3, 4, 5],\n",
       "                                        'n_estimators': [100, 200, 300]},\n",
       "                   scoring='precision_micro', verbose=1)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting up and downsampled training data to GridSearch instance\n",
    "grid_tree_rf.fit(X_links, y_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using trained model to predict on up and downsampled train set\n",
    "y_links_rand_train_preds = lr_links_grid.predict(X_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing target variables prediction against real for train set\n",
    "print(classification_report(y_links, y_links_rand_train_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating confusion matrix for y_links and y_links_rand_train_preds\n",
    "confusion_matrix(y_links, y_links_rand_train_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using trained model to predict on up and downsampled test set\n",
    "y_links_rand_test_preds = lr_links_grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.96      0.78      1954\n",
      "           1       0.49      0.08      0.14      1046\n",
      "\n",
      "    accuracy                           0.65      3000\n",
      "   macro avg       0.58      0.52      0.46      3000\n",
      "weighted avg       0.60      0.65      0.56      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing target variables prediction against real for test set\n",
    "print(classification_report(y_test, y_links_rand_test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating confusion matrix for y_test and y_links_rand_test_preds\n",
    "confusion_matrix(y_test, y_links_rand_test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new instance of Random Forest model updated with finding from first iteration\n",
    "rf_links_2 = RandomForestClassifier(n_jobs=-1, min_samples_leaf = 1, criterion = 'entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating parameter grid for Random Search\n",
    "param_grid_links_rf_2 = {  \n",
    "    'n_estimators': list(range(150,800, 50)),\n",
    "    'max_depth': list(range(3,8)),\n",
    "    'max_features': list(range(200,600,25)),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating instance of Random Search for Random Forest including param_grid_links_rf_2\n",
    "grid_tree_rf_2 = RandomizedSearchCV(rf_links_2, \n",
    "                                  param_grid_links_rf_2, \n",
    "                                  cv=10,\n",
    "                                  verbose=2,\n",
    "                                  n_jobs=-1,\n",
    "                                  scoring='precision'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed: 15.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=10,\n",
       "                   estimator=RandomForestClassifier(criterion='entropy',\n",
       "                                                    n_jobs=-1),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'max_depth': [3, 4, 5, 6, 7],\n",
       "                                        'max_features': [200, 225, 250, 275,\n",
       "                                                         300, 325, 350, 375,\n",
       "                                                         400, 425, 450, 475,\n",
       "                                                         500, 525, 550, 575],\n",
       "                                        'n_estimators': [150, 200, 250, 300,\n",
       "                                                         350, 400, 450, 500,\n",
       "                                                         550, 600, 650, 700,\n",
       "                                                         750]},\n",
       "                   scoring='precision', verbose=2)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting up and downsampled training data to Random Search instance\n",
    "grid_tree_rf_2.fit(X_links, y_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using trained model to predict on up and downsampled train set\n",
    "y_links_rand_2_train_preds = lr_links_grid.predict(X_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing target variables prediction against real for train set\n",
    "print(classification_report(y_links, y_links_rand_2_train_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating confusion matrix for y_links and y_links_rand_2_train_preds\n",
    "confusion_matrix(y_links, y_links_rand_2_train_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using trained model to predict on up and downsampled test set\n",
    "y_links_rand_2_test_preds = lr_links_grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      1.00      0.79      1954\n",
      "           1       0.00      0.00      0.00      1046\n",
      "\n",
      "    accuracy                           0.65      3000\n",
      "   macro avg       0.33      0.50      0.39      3000\n",
      "weighted avg       0.42      0.65      0.51      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing target variables prediction against real for test set\n",
    "print(classification_report(y_test, y_links_rand_2_test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating confusion matrix for y_test and y_links_rand_2_test_preds\n",
    "confusion_matrix(y_test, y_links_rand_2_test_preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
