{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-12T14:41:59.259002Z",
     "start_time": "2020-11-12T14:41:59.245156Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = 100\n",
    "\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.utils import resample\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('training_startup_data.csv', index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-12T14:36:26.542994Z",
     "start_time": "2020-11-12T14:36:26.535881Z"
    }
   },
   "outputs": [],
   "source": [
    "training_data = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-12T14:37:20.707601Z",
     "start_time": "2020-11-12T14:36:35.085650Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:\n",
      "0    12728\n",
      "1     1650\n",
      "Name: target, dtype: int64\n",
      "0    0.885241\n",
      "1    0.114759\n",
      "Name: target, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "base_logreg = LogisticRegression(random_state=42, max_iter= 10**4)\n",
    "\n",
    "y_baseline = training_data['target']\n",
    "X_baseline = training_data.drop('target', axis=1)\n",
    "\n",
    "X_train , X_test, y_train, y_test = train_test_split(X_baseline, y_baseline, test_size = 0.20, random_state=42)\n",
    "\n",
    "\n",
    "base_logreg.fit(X_train, y_train)\n",
    "\n",
    "y_log_default_test = base_logreg.predict(X_test)\n",
    "y_log_default_train = base_logreg.predict(X_train)\n",
    "\n",
    "residuals1 = np.abs(y_train - y_log_default_train)\n",
    "print('Training Data:')\n",
    "print(pd.Series(residuals1).value_counts())\n",
    "print(pd.Series(residuals1).value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-12T14:37:43.068982Z",
     "start_time": "2020-11-12T14:37:43.025583Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94     12873\n",
      "           1       0.09      0.01      0.02      1505\n",
      "\n",
      "    accuracy                           0.89     14378\n",
      "   macro avg       0.50      0.50      0.48     14378\n",
      "weighted avg       0.81      0.89      0.84     14378\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainrpt = print(classification_report(y_train, y_log_default_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-12T14:38:13.616897Z",
     "start_time": "2020-11-12T14:38:13.582801Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12711,   162],\n",
       "       [ 1488,    17]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train, y_log_default_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Sequence 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing With Class Imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downsampling Majority Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "acquired = training_data[training_data.target ==1]\n",
    "not_acquired = training_data[training_data.target ==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_acquired_downsampled = resample(not_acquired,\n",
    "                                replace = False, \n",
    "                                n_samples = (len(acquired)), \n",
    "                                random_state = 23) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([acquired, not_acquired_downsampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1875\n",
       "0    1875\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.target.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['target']\n",
    "X = df.drop('target', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_scale = ['funding_total_usd',\n",
    "                    'seed',\n",
    "                    'venture',\n",
    "                    'equity_crowdfunding',\n",
    "                    'undisclosed',\n",
    "                    'convertible_note',\n",
    "                    'debt_financing',\n",
    "                    'angel',\n",
    "                    'grant',\n",
    "                    'private_equity', \n",
    "                    'round_A', \n",
    "                    'round_B',\n",
    "                    'days_from_founding_to_funding',\n",
    "                    'time_between_first_and_last_funding']\n",
    "\n",
    "X[columns_to_scale] = scaler.fit_transform(X[columns_to_scale])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickling Scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "scaler_pickle_path = 'scaler_1.pkl'\n",
    "\n",
    "\n",
    "scaler_pickle = open(scaler_pickle_path, 'wb')\n",
    "pickle.dump(scaler, scaler_pickle)\n",
    "scaler_pickle.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled_train , X_scaled_test, y_scaled_train, y_scaled_test = train_test_split(X, y, test_size = 0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "logReg = LogisticRegression(class_weight = 'balanced',\n",
    "                            C=0.01,\n",
    "                            solver='saga', \n",
    "                            penalty='elasticnet',\n",
    "                            max_iter=2000, \n",
    "                            l1_ratio=1.0\n",
    "                            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, class_weight='balanced', l1_ratio=1.0, max_iter=2000,\n",
       "                   penalty='elasticnet', solver='saga')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logReg.fit(X_scaled_train, y_scaled_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.60      0.60      1515\n",
      "           1       0.59      0.59      0.59      1485\n",
      "\n",
      "    accuracy                           0.60      3000\n",
      "   macro avg       0.60      0.60      0.60      3000\n",
      "weighted avg       0.60      0.60      0.60      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_scaled_train_lr = logReg.predict(X_scaled_train)\n",
    "\n",
    "\n",
    "print(classification_report(y_scaled_train, y_scaled_train_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.59      0.60       364\n",
      "           1       0.62      0.63      0.62       386\n",
      "\n",
      "    accuracy                           0.61       750\n",
      "   macro avg       0.61      0.61      0.61       750\n",
      "weighted avg       0.61      0.61      0.61       750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_scaled_test_lr = logReg.predict(X_scaled_test)\n",
    "\n",
    "\n",
    "print(classification_report(y_scaled_test_lr,y_scaled_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickling Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "model_pickle_path = 'boost_model_bf_1.pkl'\n",
    "\n",
    "\n",
    "model_pickle = open(model_pickle_path, 'wb')\n",
    "pickle.dump(logReg, model_pickle)\n",
    "model_pickle.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearch Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = { \n",
    "    'solver': ['saga'],\n",
    "    'C':[.3, .5],\n",
    "    'penalty':['elasticnet'],\n",
    "    'max_iter':[200, 1000],\n",
    "    'l1_ratio':[.2, 1.0]\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_tree=GridSearchCV(LogisticRegression(), param_grid, verbose=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  7.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=LogisticRegression(), n_jobs=-1,\n",
       "             param_grid={'C': [0.3, 0.5], 'l1_ratio': [0.2, 1.0],\n",
       "                         'max_iter': [200, 1000], 'penalty': ['elasticnet'],\n",
       "                         'solver': ['saga']},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_tree.fit(X_scaled_train, y_scaled_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_tree.best_estimator_.predict(X_scaled_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.71      0.72       360\n",
      "           1       0.74      0.75      0.74       390\n",
      "\n",
      "    accuracy                           0.73       750\n",
      "   macro avg       0.73      0.73      0.73       750\n",
      "weighted avg       0.73      0.73      0.73       750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_scaled_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob = grid_tree.predict_proba(X_test)[:, 1]\n",
    "y_pred_class = np.where(y_pred_prob > 0.3, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.71      0.72       360\n",
      "           1       0.74      0.75      0.74       390\n",
      "\n",
      "    accuracy                           0.73       750\n",
      "   macro avg       0.73      0.73      0.73       750\n",
      "weighted avg       0.73      0.73      0.73       750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_scaled_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickling GridSearch Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "model_pickle_path = 'boost_model_bf_1.pkl'\n",
    "\n",
    "\n",
    "model_pickle = open(model_pickle_path, 'wb')\n",
    "pickle.dump(grid_tree.best_estimator_, model_pickle)\n",
    "model_pickle.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Sequence 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2 = pd.read_csv('training_startup_data.csv', index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_2.drop(columns = 'target')\n",
    "y = data_2.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing With Class Imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upsampling Acquired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "acquired = data[data.target == 1]\n",
    "not_acquired = data[data.target != 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "acquired_upsampled = resample(acquired,\n",
    "                              replace=True, \n",
    "                              n_samples=5000, \n",
    "                              random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "upsampled_data = pd.concat([not_acquired, acquired_upsampled])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downsampling Not Acquired"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_acquired_down = upsampled_data[upsampled_data.target != 1]\n",
    "acquired_down = upsampled_data[upsampled_data.target == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_acquired_downsampled = resample(not_acquired_down,\n",
    "                                 replace=True, \n",
    "                                 n_samples=10000, \n",
    "                                 random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced = pd.concat([acquired_down, not_acquired_downsampled])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tomek Links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_res = balanced['target']\n",
    "X_res = balanced.drop('target', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.20, random_state=23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bal, y_bal = TomekLinks().fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistc Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_2 = StandardScaler()\n",
    "\n",
    "X_scale = X_bal\n",
    "\n",
    "X_scale[columns_to_scale] = scaler_2.fit_transform(X_scale[columns_to_scale])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_lr = {\n",
    "    \n",
    "    'class_weight': [None,'balanced'],\n",
    "    'solver': ['liblinear','sag','saga'],\n",
    "    'max_iter': list(range(100,1000,25)) \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_grid = RandomizedSearchCV(lr, \n",
    "                             param_grid_lr, \n",
    "                             scoring='precision', \n",
    "                             n_jobs=-1, \n",
    "                             verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_bal, y_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lr = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.05      0.09      1954\n",
      "           1       0.35      0.98      0.52      1046\n",
      "\n",
      "    accuracy                           0.37      3000\n",
      "   macro avg       0.58      0.51      0.31      3000\n",
      "weighted avg       0.65      0.37      0.24      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3549843695727683"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.precision_score(y_test,y_pred_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 0.95\n",
    "thesh_preds = np.where(lr.predict_proba(X_test)[:,1] > THRESHOLD, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3549843695727683"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.precision_score(y_test,thesh_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iteration 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_rf = {  \n",
    "    'n_estimators': [100,200,300],\n",
    "    'criterion': ['gini','entropy'],\n",
    "    'max_depth': list(range(5,7)),\n",
    "    'max_features': list(range(100,1000,100)),\n",
    "    'min_samples_leaf': [1,2,3,4,5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_tree_rf = RandomizedSearchCV(rf, \n",
    "                                  param_grid_rf, \n",
    "                                  cv=5,\n",
    "                                  verbose=1,\n",
    "                                  n_jobs=-1,\n",
    "                                  scoring='precision_micro'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  4.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(n_jobs=-1), n_jobs=-1,\n",
       "                   param_distributions={'criterion': ['gini', 'entropy'],\n",
       "                                        'max_depth': [5, 6],\n",
       "                                        'max_features': [100, 200, 300, 400,\n",
       "                                                         500, 600, 700, 800,\n",
       "                                                         900],\n",
       "                                        'min_samples_leaf': [1, 2, 3, 4, 5],\n",
       "                                        'n_estimators': [100, 200, 300]},\n",
       "                   scoring='precision_micro', verbose=1)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_tree_rf.fit(X_bal, y_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 200,\n",
       " 'min_samples_leaf': 3,\n",
       " 'max_features': 500,\n",
       " 'max_depth': 6,\n",
       " 'criterion': 'gini'}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_tree_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7386475055835606"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_tree_rf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf_1 = grid_tree_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.96      0.78      1954\n",
      "           1       0.49      0.08      0.14      1046\n",
      "\n",
      "    accuracy                           0.65      3000\n",
      "   macro avg       0.58      0.52      0.46      3000\n",
      "weighted avg       0.60      0.65      0.56      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred_rf_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_2 = RandomForestClassifier(n_jobs=-1, min_samples_leaf = 1, criterion = 'entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_rf_2 = {  \n",
    "    'n_estimators': list(range(150,800, 50)),\n",
    "    'max_depth': list(range(3,8)),\n",
    "    'max_features': list(range(200,600,25)),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_tree_rf_2 = RandomizedSearchCV(rf_2, \n",
    "                                  param_grid_rf_2, \n",
    "                                  cv=10,\n",
    "                                  verbose=2,\n",
    "                                  n_jobs=-1,\n",
    "                                  scoring='precision'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed: 15.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=10,\n",
       "                   estimator=RandomForestClassifier(criterion='entropy',\n",
       "                                                    n_jobs=-1),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'max_depth': [3, 4, 5, 6, 7],\n",
       "                                        'max_features': [200, 225, 250, 275,\n",
       "                                                         300, 325, 350, 375,\n",
       "                                                         400, 425, 450, 475,\n",
       "                                                         500, 525, 550, 575],\n",
       "                                        'n_estimators': [150, 200, 250, 300,\n",
       "                                                         350, 400, 450, 500,\n",
       "                                                         550, 600, 650, 700,\n",
       "                                                         750]},\n",
       "                   scoring='precision', verbose=2)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_tree_rf_2.fit(X_bal, y_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.793849364607973"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_tree_rf_2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 650, 'max_features': 350, 'max_depth': 3}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_tree_rf_2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf_2 = grid_tree_rf_2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      1.00      0.79      1954\n",
      "           1       0.00      0.00      0.00      1046\n",
      "\n",
      "    accuracy                           0.65      3000\n",
      "   macro avg       0.33      0.50      0.39      3000\n",
      "weighted avg       0.42      0.65      0.51      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_rf_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
