{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "%matplotlib inline\n",
    "% matplotlib inline\n",
    "\n",
    "\n",
    "pd.options.display.max_columns = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('cleaned_dummied_startup_data.csv')\n",
    "data.drop(['Unnamed: 0', 'founded_at', 'last_funding_at', 'first_funding_at'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "status = []\n",
    "\n",
    "for val in data['status']:\n",
    "    if val == 'acquired':\n",
    "        status.append(0)\n",
    "    elif val == 'operating':\n",
    "        status.append(1)\n",
    "    else:\n",
    "        status.append(2)\n",
    "data['target'] = status        \n",
    "\n",
    "data.drop(['status'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = training_data.loc[training_data['funding_total_usd'] != ' -   ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brendanferris/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/pandas/core/generic.py:5208: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "training_data.funding_total_usd = training_data['funding_total_usd'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:\n",
      "0    13356\n",
      "1     2603\n",
      "2       17\n",
      "Name: target, dtype: int64\n",
      "0    0.836004\n",
      "1    0.162932\n",
      "2    0.001064\n",
      "Name: target, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brendanferris/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "base_logreg = LogisticRegression(random_state=42, max_iter= 10**4)\n",
    "\n",
    "y_baseline = training_data['target']\n",
    "X_baseline = training_data.drop('target', axis=1)\n",
    "\n",
    "X_train , X_test, y_train, y_test = train_test_split(X_baseline, y_baseline, test_size = 0.20, random_state=42)\n",
    "\n",
    "\n",
    "base_logreg.fit(X_train, y_train)\n",
    "\n",
    "y_log_default_test = base_logreg.predict(X_test)\n",
    "y_log_default_train = base_logreg.predict(X_train)\n",
    "\n",
    "residuals1 = np.abs(y_train - y_log_default_train)\n",
    "print('Training Data:')\n",
    "print(pd.Series(residuals1).value_counts())\n",
    "print(pd.Series(residuals1).value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      0.01      0.02      1671\n",
      "           1       0.85      0.99      0.91     13504\n",
      "           2       0.09      0.00      0.00       801\n",
      "\n",
      "    accuracy                           0.84     15976\n",
      "   macro avg       0.34      0.33      0.31     15976\n",
      "weighted avg       0.73      0.84      0.77     15976\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainrpt = print(classification_report(y_train, y_log_default_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   18,  1652,     1],\n",
       "       [  149, 13336,    19],\n",
       "       [   16,   783,     2]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train, y_log_default_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with class imbalance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downsampling the majority class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "acquired = training_data[training_data.target ==0]\n",
    "operating = training_data[training_data.target ==1]\n",
    "closed = training_data[training_data.target ==2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "operating_downsampled = resample(operating,\n",
    "                                replace = False, # sample without replacement\n",
    "                                n_samples = (len(acquired)+150), # match minority n\n",
    "                                random_state = 23) # reproducible results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([operating_downsampled, acquired, closed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2275\n",
       "0    2125\n",
       "2    1031\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.target.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['target']\n",
    "X = df.drop('target', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=23)\n",
    "X_train, y_train = sm.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    1695\n",
       "1    1695\n",
       "0    1695\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brendanferris/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "smote_lr = LogisticRegression(solver='saga')\n",
    "\n",
    "smote_lr.fit(X_train, y_train)\n",
    "\n",
    "smote_pred = smote_lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.84      0.59       530\n",
      "           1       0.48      0.31      0.38       580\n",
      "           2       0.00      0.00      0.00       248\n",
      "\n",
      "    accuracy                           0.46      1358\n",
      "   macro avg       0.31      0.38      0.32      1358\n",
      "weighted avg       0.38      0.46      0.39      1358\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainrpt = print(classification_report(y_test, smote_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['target']\n",
    "X = df.drop('target', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "scaled_X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled_train , X_scaled_test, y_scaled_train, y_scaled_test = train_test_split(scaled_X, y, test_size = 0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaled Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "logReg = LogisticRegression(class_weight = 'balanced',\n",
    "                            C=0.01,\n",
    "                            solver='saga', \n",
    "                            penalty='elasticnet',\n",
    "                            max_iter=1000, \n",
    "                            l1_ratio=1.0\n",
    "                            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, class_weight='balanced', l1_ratio=1.0, max_iter=1000,\n",
       "                   penalty='elasticnet', solver='saga')"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logReg.fit(X_scaled_train, y_scaled_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.55      0.56      1724\n",
      "           1       0.71      0.43      0.53      1800\n",
      "           2       0.34      0.67      0.45       820\n",
      "\n",
      "    accuracy                           0.52      4344\n",
      "   macro avg       0.54      0.55      0.52      4344\n",
      "weighted avg       0.59      0.52      0.53      4344\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_scaled_train_lr = logReg.predict(X_scaled_train)\n",
    "\n",
    "\n",
    "print(classification_report(y_scaled_train, y_scaled_train_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.52      0.53       401\n",
      "           1       0.71      0.44      0.54       475\n",
      "           2       0.33      0.62      0.43       211\n",
      "\n",
      "    accuracy                           0.51      1087\n",
      "   macro avg       0.52      0.53      0.50      1087\n",
      "weighted avg       0.57      0.51      0.52      1087\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_scaled_test_lr = logReg.predict(X_scaled_test)\n",
    "\n",
    "\n",
    "print(classification_report(y_scaled_test, y_scaled_test_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier()"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# objective ='multi:softmax', \n",
    "#                            colsample_bytree = 0.5, \n",
    "#                            subsample = 0.5,\n",
    "#                            learning_rate = 0.1,\n",
    "#                            max_depth = 4, \n",
    "#                            alpha = 1,\n",
    "#                            silent=1,\n",
    "#                            n_estimators = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_clf = xgb.XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(alpha=1, colsample_bytree=0.5, max_depth=4, n_estimators=50,\n",
       "              objective='multi:softprob', silent=1, subsample=0.5)"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_clf.fit(X_scaled_train, y_scaled_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = xg_clf.predict(X_scaled_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.79      0.70      1724\n",
      "           1       0.69      0.68      0.69      1800\n",
      "           2       0.66      0.33      0.44       820\n",
      "\n",
      "    accuracy                           0.66      4344\n",
      "   macro avg       0.66      0.60      0.61      4344\n",
      "weighted avg       0.66      0.66      0.65      4344\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_scaled_train, train_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = xg_clf.predict(X_scaled_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.74      0.65       401\n",
      "           1       0.65      0.65      0.65       475\n",
      "           2       0.55      0.26      0.35       211\n",
      "\n",
      "    accuracy                           0.61      1087\n",
      "   macro avg       0.59      0.55      0.55      1087\n",
      "weighted avg       0.60      0.61      0.59      1087\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_scaled_test, test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective':['multi:softmax'], \n",
    "    'colsample_bytree': [0.5, 0.2], \n",
    "    'subsample':[0.5],\n",
    "    'learning_rate':[0.1],\n",
    "    'max_depth':[4], \n",
    "    'alpha':[5, 10],\n",
    "    'scoring':['recall'],\n",
    "    'n_estimators':[125, 200]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brendanferris/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/model_selection/_search.py:282: UserWarning: The total space of parameters 8 is smaller than n_iter=10. Running 8 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed: 14.2min finished\n"
     ]
    }
   ],
   "source": [
    "clf = RandomizedSearchCV(xg_clf, params, random_state=0, n_jobs=-1, verbose=1, cv=5)\n",
    "search = clf.fit(X_scaled_train, y_scaled_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subsample': 0.5,\n",
       " 'scoring': 'recall',\n",
       " 'objective': 'multi:softmax',\n",
       " 'n_estimators': 200,\n",
       " 'max_depth': 4,\n",
       " 'learning_rate': 0.1,\n",
       " 'colsample_bytree': 0.5,\n",
       " 'alpha': 5}"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
