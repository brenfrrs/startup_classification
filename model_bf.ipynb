{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "%matplotlib inline\n",
    "% matplotlib inline\n",
    "\n",
    "\n",
    "pd.options.display.max_columns = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('cleaned_dummied_startup_data.csv')\n",
    "data.drop(['Unnamed: 0', 'founded_at', 'last_funding_at', 'first_funding_at'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "status = []\n",
    "\n",
    "for val in data['status']:\n",
    "    if val == 'acquired':\n",
    "        status.append(0)\n",
    "    elif val == 'operating':\n",
    "        status.append(1)\n",
    "    else:\n",
    "        status.append(2)\n",
    "data['target'] = status        \n",
    "\n",
    "data.drop(['status'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = training_data.loc[training_data['funding_total_usd'] != ' -   ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brendanferris/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/pandas/core/generic.py:5208: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "training_data.funding_total_usd = training_data['funding_total_usd'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:\n",
      "0    13356\n",
      "1     2603\n",
      "2       17\n",
      "Name: target, dtype: int64\n",
      "0    0.836004\n",
      "1    0.162932\n",
      "2    0.001064\n",
      "Name: target, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brendanferris/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "base_logreg = LogisticRegression(random_state=42, max_iter= 10**4)\n",
    "\n",
    "y_baseline = training_data['target']\n",
    "X_baseline = training_data.drop('target', axis=1)\n",
    "\n",
    "X_train , X_test, y_train, y_test = train_test_split(X_baseline, y_baseline, test_size = 0.20, random_state=42)\n",
    "\n",
    "\n",
    "base_logreg.fit(X_train, y_train)\n",
    "\n",
    "y_log_default_test = base_logreg.predict(X_test)\n",
    "y_log_default_train = base_logreg.predict(X_train)\n",
    "\n",
    "residuals1 = np.abs(y_train - y_log_default_train)\n",
    "print('Training Data:')\n",
    "print(pd.Series(residuals1).value_counts())\n",
    "print(pd.Series(residuals1).value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      0.01      0.02      1671\n",
      "           1       0.85      0.99      0.91     13504\n",
      "           2       0.09      0.00      0.00       801\n",
      "\n",
      "    accuracy                           0.84     15976\n",
      "   macro avg       0.34      0.33      0.31     15976\n",
      "weighted avg       0.73      0.84      0.77     15976\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainrpt = print(classification_report(y_train, y_log_default_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   18,  1652,     1],\n",
       "       [  149, 13336,    19],\n",
       "       [   16,   783,     2]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train, y_log_default_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with class imbalance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downsampling the majority class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "acquired = training_data[training_data.target ==0]\n",
    "operating = training_data[training_data.target ==1]\n",
    "closed = training_data[training_data.target ==2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "operating_downsampled = resample(operating,\n",
    "                                replace = False, # sample without replacement\n",
    "                                n_samples = (len(acquired)+150), # match minority n\n",
    "                                random_state = 23) # reproducible results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([operating_downsampled, acquired, closed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2275\n",
       "0    2125\n",
       "2    1031\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.target.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['target']\n",
    "X = df.drop('target', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=23)\n",
    "X_train, y_train = sm.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    1695\n",
       "1    1695\n",
       "0    1695\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brendanferris/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "smote_lr = LogisticRegression(solver='saga')\n",
    "\n",
    "smote_lr.fit(X_train, y_train)\n",
    "\n",
    "smote_pred = smote_lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.84      0.59       530\n",
      "           1       0.48      0.31      0.38       580\n",
      "           2       0.00      0.00      0.00       248\n",
      "\n",
      "    accuracy                           0.46      1358\n",
      "   macro avg       0.31      0.38      0.32      1358\n",
      "weighted avg       0.38      0.46      0.39      1358\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainrpt = print(classification_report(y_test, smote_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['target']\n",
    "X = df.drop('target', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "scaled_X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled_train , X_scaled_test, y_scaled_train, y_scaled_test = train_test_split(scaled_X, y, test_size = 0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaled Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "logReg = LogisticRegression(class_weight = 'balanced',\n",
    "                            C=0.01,\n",
    "                            solver='saga', \n",
    "                            penalty='elasticnet',\n",
    "                            max_iter=1000, \n",
    "                            l1_ratio=1.0\n",
    "                            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, class_weight='balanced', l1_ratio=1.0, max_iter=1000,\n",
       "                   penalty='elasticnet', solver='saga')"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logReg.fit(X_scaled_train, y_scaled_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.55      0.56      1724\n",
      "           1       0.71      0.43      0.53      1800\n",
      "           2       0.34      0.67      0.45       820\n",
      "\n",
      "    accuracy                           0.52      4344\n",
      "   macro avg       0.54      0.55      0.52      4344\n",
      "weighted avg       0.59      0.52      0.53      4344\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_scaled_train_lr = logReg.predict(X_scaled_train)\n",
    "\n",
    "\n",
    "print(classification_report(y_scaled_train, y_scaled_train_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.52      0.53       401\n",
      "           1       0.71      0.44      0.54       475\n",
      "           2       0.33      0.62      0.43       211\n",
      "\n",
      "    accuracy                           0.51      1087\n",
      "   macro avg       0.52      0.53      0.50      1087\n",
      "weighted avg       0.57      0.51      0.52      1087\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_scaled_test_lr = logReg.predict(X_scaled_test)\n",
    "\n",
    "\n",
    "print(classification_report(y_scaled_test, y_scaled_test_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier()"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_clf = xgb.XGBClassifier(objective ='multi:softmax', \n",
    "                           colsample_bytree = 0.5, \n",
    "                           subsample = 0.5,\n",
    "                           learning_rate = 0.1,\n",
    "                           max_depth = 4, \n",
    "                           alpha = 1,\n",
    "                           silent=1,\n",
    "                           #scale_pos_weight= titanic['Survived'].mean(),\n",
    "                           n_estimators = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(alpha=1, colsample_bytree=0.5, max_depth=4, n_estimators=500,\n",
       "              objective='multi:softprob', silent=1, subsample=0.5)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_clf.fit(X_scaled_train, y_scaled_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = xg_clf.predict(X_scaled_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.90      0.86      1724\n",
      "           1       0.88      0.87      0.87      1800\n",
      "           2       0.83      0.72      0.77       820\n",
      "\n",
      "    accuracy                           0.85      4344\n",
      "   macro avg       0.85      0.83      0.84      4344\n",
      "weighted avg       0.85      0.85      0.85      4344\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_scaled_train, train_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = xg_clf.predict(X_scaled_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.68      0.64       401\n",
      "           1       0.68      0.70      0.69       475\n",
      "           2       0.52      0.36      0.42       211\n",
      "\n",
      "    accuracy                           0.63      1087\n",
      "   macro avg       0.60      0.58      0.59      1087\n",
      "weighted avg       0.62      0.63      0.62      1087\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_scaled_test, test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'graphviz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-197-9a31dc31557b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgraphviz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_tree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplot_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxg_clf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'graphviz'"
     ]
    }
   ],
   "source": [
    "import graphviz\n",
    "from xgboost import plot_tree\n",
    "\n",
    "plot_tree(xg_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
      "Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.8.5\n",
      "  latest version: 4.9.1\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Users/brendanferris/opt/anaconda3/envs/learn-env\n",
      "\n",
      "  added / updated specs:\n",
      "    - graphviz\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    ca-certificates-2020.10.14 |                0         121 KB\n",
      "    cairo-1.14.12              |       hc4e6be7_4         860 KB\n",
      "    certifi-2020.6.20          |     pyhd3eb1b0_3         155 KB\n",
      "    fontconfig-2.13.0          |       h5d5b041_1         202 KB\n",
      "    fribidi-1.0.10             |       haf1e3a3_0          63 KB\n",
      "    graphite2-1.3.14           |       h38d11af_0          80 KB\n",
      "    graphviz-2.40.1            |       hefbbd9a_2         6.3 MB\n",
      "    harfbuzz-1.8.8             |       hb8d4a28_0         414 KB\n",
      "    libxml2-2.9.10             |       h7cdb67c_3         1.1 MB\n",
      "    openssl-1.1.1h             |       haf1e3a3_0         2.2 MB\n",
      "    pango-1.42.4               |       h7e27002_1         456 KB\n",
      "    pixman-0.40.0              |       haf1e3a3_0         340 KB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        12.3 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  cairo              pkgs/main/osx-64::cairo-1.14.12-hc4e6be7_4\n",
      "  expat              pkgs/main/osx-64::expat-2.2.10-hb1e8313_2\n",
      "  fontconfig         pkgs/main/osx-64::fontconfig-2.13.0-h5d5b041_1\n",
      "  fribidi            pkgs/main/osx-64::fribidi-1.0.10-haf1e3a3_0\n",
      "  gettext            pkgs/main/osx-64::gettext-0.19.8.1-h15daf44_3\n",
      "  glib               pkgs/main/osx-64::glib-2.63.1-hd977a24_0\n",
      "  graphite2          pkgs/main/osx-64::graphite2-1.3.14-h38d11af_0\n",
      "  graphviz           pkgs/main/osx-64::graphviz-2.40.1-hefbbd9a_2\n",
      "  harfbuzz           pkgs/main/osx-64::harfbuzz-1.8.8-hb8d4a28_0\n",
      "  icu                pkgs/main/osx-64::icu-58.2-h0a44026_3\n",
      "  jpeg               pkgs/main/osx-64::jpeg-9b-he5867d9_2\n",
      "  libiconv           pkgs/main/osx-64::libiconv-1.16-h1de35cc_0\n",
      "  libtiff            pkgs/main/osx-64::libtiff-4.1.0-hcb84e12_1\n",
      "  libxml2            pkgs/main/osx-64::libxml2-2.9.10-h7cdb67c_3\n",
      "  lz4-c              pkgs/main/osx-64::lz4-c-1.9.2-h79c402e_3\n",
      "  pango              pkgs/main/osx-64::pango-1.42.4-h7e27002_1\n",
      "  pcre               pkgs/main/osx-64::pcre-8.44-hb1e8313_0\n",
      "  pixman             pkgs/main/osx-64::pixman-0.40.0-haf1e3a3_0\n",
      "  zstd               pkgs/main/osx-64::zstd-1.4.5-h41d2c2f_0\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates    conda-forge::ca-certificates-2020.6.2~ --> pkgs/main::ca-certificates-2020.10.14-0\n",
      "  certifi            conda-forge/osx-64::certifi-2020.6.20~ --> pkgs/main/noarch::certifi-2020.6.20-pyhd3eb1b0_3\n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  openssl                                       conda-forge --> pkgs/main\n",
      "\n",
      "\n",
      "Proceed ([y]/n)? "
     ]
    }
   ],
   "source": [
    "!conda install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
